{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWuH0ZW2JXX4"
      },
      "source": [
        "# Classification d'images avec *tf.keras*\n",
        "\n",
        "Dans ce projet, on va implémenter des réseaux neuronaux en utilisant les API de Keras.\n",
        "Nous utiliserons l'implémentation de Keras contenu dans TensorFlow, *tf.keras*.\n",
        "\n",
        "Lien vers la documentation de [keras.io](https://keras.io/).\n",
        "\n",
        "Tout le code que nous écrirons dans ce notebook fonctionnera avec la librairie Keras. Nous n'utiliserons pas de lignes spécifiques à TensorFlow.\n",
        "\n",
        "Pour rappel : la seule différence entre la librairie Keras et le Keras inclus dans TensorFlow est la façon d'importer Keras :\n",
        "\n",
        "```python\n",
        "# keras.io code:\n",
        "from keras.layers import Dense\n",
        "output_layer = Dense(10)\n",
        "\n",
        "# corresponding tf.keras code:\n",
        "from tensorflow.keras.layers import Dense\n",
        "output_layer = Dense(10)\n",
        "\n",
        "# or:\n",
        "from tensorflow import keras\n",
        "output_layer = keras.layers.Dense(10)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnvE4gHBJXX8"
      },
      "source": [
        "#◢  Import & Vérification des versions des librairies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LDs4gtdfJXX9"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "%tensorflow_version 2.x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5arxEGTVJXYC"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras  # tf.keras\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66EAwUnfJXYG"
      },
      "outputs": [],
      "source": [
        "print(\"python\", sys.version)\n",
        "for module in tf, keras, pd, np, mpl:\n",
        "    print(module.__name__, module.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDFQLo6fJXYJ"
      },
      "outputs": [],
      "source": [
        "assert sys.version_info >= (3, 5) # Python ≥3.5 required\n",
        "assert tf.__version__ >= \"2.0\"    # TensorFlow ≥2.0 required"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2muDbRUJXYM"
      },
      "source": [
        "#◢  Chargement du jeu de données MNIST\n",
        "\n",
        "Keras permet de charger de nombreux datasets avec `keras.datasets`.\n",
        "Nous utiliserons le jeu de données MNIST *Modifier ou Mixed National Institute of Standards and Technology*, qui est une base de données de chiffres manuscrits.\n",
        "\n",
        "\n",
        "La base MNIST est devenu un test standard. Elle regroupe 60000 images d'apprentissage et 10000 images de test, issues d'une base de données antérieure, appelée simplement NIST1. \n",
        "Ces images sont en noir et blanc, normalisées centrées et de 28 pixels de côté.\n",
        "\n",
        "Pour l’historique de la création de cette base, voir [Yann LeCun](http://yann.lecun.com/exdb/mnist/).\n",
        "\n",
        "Séparez le jeu de données d'entrainement en :\n",
        "- un jeu de validation contenant 5000 images\n",
        "- un jeu d'entrainement contenant 55000 images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EetAUOJPJXYN"
      },
      "outputs": [],
      "source": [
        "mnist = keras.datasets.mnist\n",
        "(X_train_full, y_train_full), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3R5BBPoJXYQ"
      },
      "source": [
        "#◢  Exploration des données"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heInchNIJXYQ"
      },
      "source": [
        "Nous avons désormais 3 jeux de données :\n",
        "- Le jeu de données d'entrainement qui contient 55000 images de tailles 28x28 pixels\n",
        "- Le jeu de données de validation qui contient 5000 images de tailles 28x28 pixels\n",
        "- Le jeu de données de test qui contient 10000 images de tailles 28x28 pixels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0uGU6211JXYR"
      },
      "outputs": [],
      "source": [
        "#Affichage de la taille du X_train\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikNhJzbBjRw0"
      },
      "outputs": [],
      "source": [
        "#Affichage de la taille du X_valid\n",
        "X_valid.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G21wUNEqjRna"
      },
      "outputs": [],
      "source": [
        "#Affichage de la taille du X_test\n",
        "X_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86ync6j5JXYU"
      },
      "source": [
        "Chaque pixel a une valeur comprise entre 0 et 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSz9yXG1JXYV"
      },
      "outputs": [],
      "source": [
        "X_train[0][10:15]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzmW71hFJXYX"
      },
      "source": [
        "Nous pouvons afficher une image en utilisant la fonction de Matplotlib `imshow()`, avec la carte des couleurs `'binary'` :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNfTlmzKJXYY"
      },
      "outputs": [],
      "source": [
        "plt.imshow(X_train[1], cmap=\"binary\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTIADpMoJXYb"
      },
      "source": [
        "Les labels sont des classes allant de 0 à 9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ME6F0R5oJXYb"
      },
      "outputs": [],
      "source": [
        "y_train[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eX5bTZD0JXYe"
      },
      "source": [
        "Regardons quelques images du jeu de données :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwF7rb7oJXYf"
      },
      "outputs": [],
      "source": [
        "n_rows = 5\n",
        "n_cols = 10\n",
        "plt.figure(figsize=(n_cols*2, n_rows*2))\n",
        "for row in range(n_rows):\n",
        "    for col in range(n_cols):\n",
        "        index = n_cols * row + col\n",
        "        plt.subplot(n_rows, n_cols, index + 1)\n",
        "        plt.imshow(X_train[index], cmap=\"binary\", interpolation=\"nearest\")\n",
        "        plt.axis('off')\n",
        "        plt.title('Chiffre ' + str(y_train[index]))\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9W4nc7QJXYh"
      },
      "source": [
        "#◢  Pré-Processing\n",
        "Les images étant dans l'échelle [grayscale](https://en.wikipedia.org/wiki/Grayscale), les valeurs varient de 0 à 255.\n",
        "\n",
        "Afin de normaliser (centrer) les données, nous allons implémnter la fonction Min-Max scaling dans la fonction `normalize_grayscale()`. Après la mise à l'échelle, les valeurs des pixels des données d'entrée iront de 0.1 à 0.9.\n",
        "\n",
        "Min-Max Scaling:\n",
        "$\n",
        "X'=a+{\\frac {\\left(X-X_{\\min }\\right)\\left(b-a\\right)}{X_{\\max }-X_{\\min }}}\n",
        "$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1R6KJirAJXYi"
      },
      "outputs": [],
      "source": [
        "def normalize_grayscale(image_data):\n",
        "    \"\"\"\n",
        "    Normalize the image data with Min-Max scaling to a range of [0.1, 0.9]\n",
        "    :param image_data: The image data to be normalized\n",
        "    :return: Normalized image data\n",
        "    \"\"\"\n",
        "    #Implementation of Min-Max scaling for grayscale image data :\n",
        "\n",
        "    a = 0.1\n",
        "    b = 0.9\n",
        "    image_data_min = image_data.min()\n",
        "    image_data_max = image_data.max()\n",
        "    return a + ((image_data - image_data_min)*(b-a))/(image_data_max - image_data_min)\n",
        "\n",
        "# Test Cases\n",
        "np.testing.assert_array_almost_equal(\n",
        "    normalize_grayscale(np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 255])),\n",
        "    [0.1, 0.103137254902, 0.106274509804, 0.109411764706, 0.112549019608, 0.11568627451, 0.118823529412, 0.121960784314,\n",
        "     0.125098039216, 0.128235294118, 0.13137254902, 0.9],\n",
        "    decimal=3)\n",
        "np.testing.assert_array_almost_equal(\n",
        "    normalize_grayscale(np.array([0, 1, 10, 20, 30, 40, 233, 244, 254,255])),\n",
        "    [0.1, 0.103137254902, 0.13137254902, 0.162745098039, 0.194117647059, 0.225490196078, 0.830980392157, 0.865490196078,\n",
        "     0.896862745098, 0.9])\n",
        "\n",
        "\n",
        "train_features = normalize_grayscale(X_train)\n",
        "val_features = normalize_grayscale(X_valid)\n",
        "test_features = normalize_grayscale(X_test)\n",
        "\n",
        "print('Tests Passed!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vC2lvBnNJXYk"
      },
      "source": [
        "#◢  Construction d'un modèle \n",
        "\n",
        "Construction d'un modèle `Sequential` avec l'API `keras.models.Sequential`, sans aucun argument, et avec 3 couches en utilisant la méthode `add()` :\n",
        "  * Une couche `Flatten` (`keras.layers.Flatten`) pour convertir chaque image de taille 28x28 image en un simple tableau de 784 pixels. Comme cette couche est la première de votre modèle, vous devez spécifier l'argument `input_shape`.\n",
        "  * Une couche `Dense` (`keras.layers.Dense`) avec 50 neurones (également appelés units), et la fonction d'activation `\"relu\"`.\n",
        "  * Pour finir une couche `Dense` avec 10 neurones (1 par classe), et avec la fonction d'activation `\"softmax\"` activation pour s'assurer que la somme de toutes les probabilités des classe estimées pour chaque image est égale à 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGG516sJJXYl"
      },
      "outputs": [],
      "source": [
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=[28,28]))\n",
        "model.add(keras.layers.Dense(50, activation=\"relu\"))\n",
        "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQLICr8JJXYs"
      },
      "source": [
        "Affichons la liste des couches : "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBzN-R23JXYt"
      },
      "outputs": [],
      "source": [
        "model.layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2QVrm2rJXYu"
      },
      "source": [
        "Faisons un `summary` du modèle :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oHGst-pXJXYv"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7WSu1YtJXYx"
      },
      "source": [
        "#◢  Compilation du modèle\n",
        "\n",
        "Nous utiliserons : \n",
        "La fonction de cout `\"sparse_categorical_crossentropy\"`, l'optimiseur suivant `keras.optimizers.SGD(lr=0.01)`(stochastic gradient descent avec un learning rate à 0.01) et la métrique : `metrics=[\"accuracy\"]`. \n",
        "\n",
        "**Note**: Dans la documenation de Keras, vous trouverez d'autres fontions de cout `keras.losses`, d'autres métriques `keras.metrics` et d'autres optimiseurs `keras.optimizer`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "xetpm-WFJXYx",
        "outputId": "4d51c51b-3d56-431f-d5a5-6d220da4a308"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f118d100fc86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model.compile(loss=\"sparse_categorical_crossentropy\",\n\u001b[0m\u001b[1;32m      2\u001b[0m              \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m              metrics=[\"accuracy\"])\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "             optimizer=keras.optimizers.SGD(lr=0.01),\n",
        "             metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_nJmnSiJXY0"
      },
      "source": [
        "#◢  Entrainement du modèle\n",
        "\n",
        "Définissons :\n",
        "- le nombre d'epochs `epochs=5`\n",
        "- les données de validation `validation_data=(val_features, y_valid)`\n",
        "\n",
        "**Note**: La méthode `fit()` retourne un objet `History` qui contient les statistiques d'entrainement. N'oubliez pas de récupérer cet objet (`history = model.fit(...)`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJV1ctEqJXY0"
      },
      "outputs": [],
      "source": [
        "history = model.fit(train_features, y_train, epochs=5,\n",
        "                    validation_data=(val_features, y_valid))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQ5o3ptgJXY2"
      },
      "source": [
        "Regardons les valeurs de la fonction de cout et de l'accuracy sur les 2 jeux de données (train et validation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zGEselIGJXY3"
      },
      "outputs": [],
      "source": [
        "def plot_learning_curves(history):\n",
        "    pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
        "    plt.grid(True)\n",
        "    plt.gca().set_ylim(0, 1)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obsCVKkeJXY5"
      },
      "outputs": [],
      "source": [
        "plot_learning_curves(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yT44N9UgJXY6"
      },
      "source": [
        "Relancez `model.fit()` avec 3 epochs, que se passe-t-il ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQts_qH3JXY7"
      },
      "outputs": [],
      "source": [
        "history = model.fit(train_features, y_train, epochs=3,\n",
        "                    validation_data=(val_features, y_valid))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhQCHGfVJXY9"
      },
      "source": [
        "#◢  Evaluation du modèle\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ym2wJr6kJXY-"
      },
      "outputs": [],
      "source": [
        "model.evaluate(test_features, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oULxuai7JXY_"
      },
      "source": [
        "#◢  Prédiction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_9GWhVDJXZA"
      },
      "outputs": [],
      "source": [
        "y_proba = model.predict(test_features)\n",
        "y_proba[:10].round(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfIek4fhJXZC"
      },
      "source": [
        "A partir des probabilités des différentes valeurs, déduisons-en la valeur prédite (celle qui a le % maximum => utilisez la fonction `argmax`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hy1Szri6JXZD"
      },
      "outputs": [],
      "source": [
        "y_pred = y_proba.argmax(axis=1)\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haJ1F0EBJXZF"
      },
      "source": [
        "Utilisons la méthode `predict_classes()` de la classe `model` en passant en paramètre `test_features`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1_HK0E-JXZF"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict_classes(test_features)\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YC_JNEwCJXZH"
      },
      "source": [
        "#◢  Visualisation des prédictions \n",
        "\n",
        "Méthodes utilitaires pour afficher une image et un bar chart représentant la probabilité des prédictions pour chaque chiffre de 0 à 9 (les prédictions en bleu sont les prédictions correctes et en rouge celles incorrectes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvsEAuAkJXZI"
      },
      "outputs": [],
      "source": [
        "def plot_prediction_image(predictions_array, true_label, img):\n",
        "\n",
        "    plt.imshow(img, cmap=plt.cm.binary)\n",
        "\n",
        "    predicted_label = np.argmax(predictions_array)\n",
        "    if predicted_label == true_label:\n",
        "        color = 'blue'\n",
        "    else:\n",
        "        color = 'red'\n",
        "\n",
        "    plt.xlabel(\"Chiffre prédit {} {:2.0f}% ({})\".format(predicted_label,\n",
        "                                                        np.max(predictions_array) *100,\n",
        "                                                        true_label),\n",
        "                                                        color=color)\n",
        "    \n",
        "def plot_prediction_bar_chart(predictions_array, true_label, img):\n",
        "    thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
        "    plt.ylim([0, 1])\n",
        "    plt.grid(False)\n",
        "    plt.xticks(range(10))\n",
        "    predicted_label = np.argmax(predictions_array)\n",
        "\n",
        "    thisplot[predicted_label].set_color('red')\n",
        "    thisplot[true_label].set_color('blue')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbGBBUCuJXZK"
      },
      "source": [
        "Affichage de l'image à prédire et de la probabilité des prédictions pour chaque chiffre de 0 à 9 pour la première image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBk5rB-TJXZL"
      },
      "outputs": [],
      "source": [
        "    ### SOLUTION ###\n",
        "i = 1\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.subplot(1,2,1)\n",
        "plot_prediction_image(y_proba[i], y_test[i], X_test[i])\n",
        "plt.subplot(1,2,2)\n",
        "plot_prediction_bar_chart(y_proba[i], y_test[i], X_test[i])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09DOSkkyJXZM"
      },
      "source": [
        "## Affichons les 20 premiers chiffres et visualisons les prédictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xill_-RbY5fP"
      },
      "outputs": [],
      "source": [
        "### SOLUTION ###\n",
        "num_rows = 8\n",
        "num_cols = 5\n",
        "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
        "\n",
        "for row in range(num_rows):\n",
        "    for col in range(num_cols):\n",
        "        index = num_cols * row + col\n",
        "        plt.subplot(num_rows, 2*num_cols, 2*index+1)\n",
        "        plot_prediction_image(y_proba[index], y_test[index], X_test[index])\n",
        "        plt.subplot(num_rows, 2*num_cols, 2*index+2)\n",
        "        plot_prediction_bar_chart(y_proba[index], y_test[index], X_test[index])\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diJfR5QjJXZP"
      },
      "source": [
        "## Focus sur les images mal prédites"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5bhdvkBJXZQ"
      },
      "outputs": [],
      "source": [
        "y_proba_false = y_proba[y_pred != y_test]\n",
        "y_test_false = y_test[y_pred != y_test]\n",
        "X_test_false = X_test[y_pred != y_test]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_tr5-YTIJXZS"
      },
      "outputs": [],
      "source": [
        "num_rows = 8\n",
        "num_cols = 5\n",
        "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
        "for row in range(num_rows):\n",
        "    for col in range(num_cols):\n",
        "        index = num_cols * row + col\n",
        "        plt.subplot(num_rows, 2*num_cols, 2*index+1)\n",
        "        plot_prediction_image(y_proba_false[index], y_test_false[index], X_test_false[index])\n",
        "        plt.subplot(num_rows, 2*num_cols, 2*index+2)\n",
        "        plot_prediction_bar_chart(y_proba_false[index], y_test_false[index], X_test_false[index])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}