{"cells":[{"cell_type":"markdown","metadata":{"id":"9LP4VkHlsqev"},"source":["# RNNs - Sequence classification"]},{"cell_type":"markdown","metadata":{"id":"maENvb2xsqey"},"source":["In this notebook you will learn how to build Recurrent Neural Networks (RNNs) for sequence classification.\n","\n","**Objectif : build RNN models for sequence classification.**\n","- 1 - Sequence classification: sentiment analysis => IMDB movie reviews, for binary sentiment analysis (positive review or negative review)\n","    - Train a baseline model using scikit learn pipelines\n","    - Create a sequence classifier using a LSTM model\n","- 2 - Bidirectional RNN"]},{"cell_type":"markdown","metadata":{"id":"D7Ex_KdCsqez"},"source":["## Imports"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"xSsaNWP4sqe3","executionInfo":{"status":"ok","timestamp":1672837816539,"user_tz":-60,"elapsed":3230,"user":{"displayName":"Alexia Audevart","userId":"09723170522858788865"}}},"outputs":[],"source":["import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import pandas as pd\n","import sklearn\n","import sys\n","import tensorflow as tf\n","from tensorflow import keras\n","import time"]},{"cell_type":"markdown","metadata":{"id":"kObo5cxasqfA"},"source":["## â—¢ 1 Sequence classification"]},{"cell_type":"markdown","metadata":{"id":"EuETJGrJsqfA"},"source":["Let's load the IMDB movie reviews, for binary sentiment analysis (positive review or negative review)\n","\n","Use Keras Datasets API : https://keras.io/datasets/\n"]},{"cell_type":"markdown","metadata":{"id":"9zf3d3zDsqfB"},"source":["We only want the 10,000 most common words:"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"33inoa_YsqfD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672837825131,"user_tz":-60,"elapsed":8596,"user":{"displayName":"Alexia Audevart","userId":"09723170522858788865"}},"outputId":"26ae1020-b922-46ac-8792-da488c817452"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n","17464789/17464789 [==============================] - 0s 0us/step\n"]}],"source":["num_words = 10000\n","(X_train, y_train), (X_test, y_test) = keras.datasets.imdb.load_data(num_words=num_words)"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"WxL769zguWj8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672837825131,"user_tz":-60,"elapsed":4,"user":{"displayName":"Alexia Audevart","userId":"09723170522858788865"}},"outputId":"d2f8f776-38b9-4bd2-c2f2-ee29a9139414"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32])],\n","      dtype=object)"]},"metadata":{},"execution_count":3}],"source":["X_train[:1]"]},{"cell_type":"markdown","metadata":{"id":"sBkxSsfasqfF"},"source":["Let's also get the word index (word to word id):"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"yfh3XpVAsqfG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672837866567,"user_tz":-60,"elapsed":252,"user":{"displayName":"Alexia Audevart","userId":"09723170522858788865"}},"outputId":"98d50791-83d8-4506-d7a1-3219602d59c1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n","1641221/1641221 [==============================] - 0s 0us/step\n"]}],"source":["word_index = keras.datasets.imdb.get_word_index()"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"7pmHT5DYuHNm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672837867890,"user_tz":-60,"elapsed":5,"user":{"displayName":"Alexia Audevart","userId":"09723170522858788865"}},"outputId":"caaf03b4-6bc0-47c6-fec6-9b7621b9d35c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["370"]},"metadata":{},"execution_count":5}],"source":["word_index[\"awful\"]"]},{"cell_type":"markdown","metadata":{"id":"EDRBWVhosqfI"},"source":["And let's create a reverse index (word id to word). Three special id words  are added:"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"6urGEr45sqfJ","executionInfo":{"status":"ok","timestamp":1672837893141,"user_tz":-60,"elapsed":224,"user":{"displayName":"Alexia Audevart","userId":"09723170522858788865"}}},"outputs":[],"source":["reverse_index = {word_id + 3: word for word, word_id in word_index.items()}\n","reverse_index[0] = \"<pad>\" # padding\n","reverse_index[1] = \"<sos>\" # start of sequence\n","reverse_index[2] = \"<oov>\" # out-of-vocabulary\n","reverse_index[3] = \"<unk>\" # unknown"]},{"cell_type":"markdown","metadata":{"id":"4eZxdgJksqfO"},"source":["Let's write a little function to decode reviews:"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"LXuxjNX1sqfO","executionInfo":{"status":"ok","timestamp":1672837895172,"user_tz":-60,"elapsed":209,"user":{"displayName":"Alexia Audevart","userId":"09723170522858788865"}}},"outputs":[],"source":["def decode_review(word_ids):\n","    return \" \".join([reverse_index.get(word_id, \"<err>\") for word_id in word_ids])"]},{"cell_type":"markdown","metadata":{"id":"LiaXLDINsqfR"},"source":["Let's look at a review:"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"7kBKICbisqfS","colab":{"base_uri":"https://localhost:8080/","height":199},"executionInfo":{"status":"ok","timestamp":1672837898939,"user_tz":-60,"elapsed":241,"user":{"displayName":"Alexia Audevart","userId":"09723170522858788865"}},"outputId":"8c7a602e-b3ef-4019-8663-2a219dd402ab"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"<sos> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <oov> is an amazing actor and now the same being director <oov> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <oov> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <oov> to the two little boy's that played the <oov> of norman and paul they were just brilliant children are often left out of the <oov> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":8}],"source":["decode_review(X_train[0])"]},{"cell_type":"markdown","metadata":{"id":"GUKmudxksqfU"},"source":["It seems very positive, let's look at the target (0=negative review, 1=positive review):"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"6QNApgARsqfV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672837926205,"user_tz":-60,"elapsed":245,"user":{"displayName":"Alexia Audevart","userId":"09723170522858788865"}},"outputId":"289e0981-bbec-40e7-e8cb-1db2c0fa187b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{},"execution_count":9}],"source":["y_train[0]"]},{"cell_type":"markdown","metadata":{"id":"18Y7jY38sqfX"},"source":["And another review:"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"Ve97UldFsqfY","colab":{"base_uri":"https://localhost:8080/","height":199},"executionInfo":{"status":"ok","timestamp":1672837930066,"user_tz":-60,"elapsed":4,"user":{"displayName":"Alexia Audevart","userId":"09723170522858788865"}},"outputId":"7cf14af5-85be-40c4-ac52-9bf91288bb50"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"<sos> big hair big boobs bad music and a giant safety pin these are the words to best describe this terrible movie i love cheesy horror movies and i've seen hundreds but this had got to be on of the worst ever made the plot is paper thin and ridiculous the acting is an abomination the script is completely laughable the best is the end showdown with the cop and how he worked out who the killer is it's just so damn terribly written the clothes are sickening and funny in equal <oov> the hair is big lots of boobs <oov> men wear those cut <oov> shirts that show off their <oov> sickening that men actually wore them and the music is just <oov> trash that plays over and over again in almost every scene there is trashy music boobs and <oov> taking away bodies and the gym still doesn't close for <oov> all joking aside this is a truly bad film whose only charm is to look back on the disaster that was the 80's and have a good old laugh at how bad everything was back then\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":10}],"source":["decode_review(X_train[1])"]},{"cell_type":"markdown","metadata":{"id":"x1XIqxp0sqfa"},"source":["Very negative! Let's check the target:"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"VY5jeZgTsqfb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672837931465,"user_tz":-60,"elapsed":5,"user":{"displayName":"Alexia Audevart","userId":"09723170522858788865"}},"outputId":"17bd5b76-d731-4840-a4df-41550645a6ec"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":11}],"source":["y_train[1]"]},{"cell_type":"markdown","metadata":{"id":"k5qzicUSsqfe"},"source":["### 1-1 Train a baseline model\n","\n","Train and evaluate a baseline model using ScikitLearn. \n","\n","You will need to create a pipeline with :\n","- a `CountVectorizer` (The `CountVectorizer` transformer expects text as input)\n","- a `TfidfTransformer`\n","- and a `SGDClassifier`. \n","\n","So let's create a text version of the training set and test set:"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"Mk_GxJPFsqfe","executionInfo":{"status":"ok","timestamp":1672837947471,"user_tz":-60,"elapsed":1791,"user":{"displayName":"Alexia Audevart","userId":"09723170522858788865"}}},"outputs":[],"source":["X_train_text = [decode_review(words_ids) for words_ids in X_train]\n","X_test_text = [decode_review(words_ids) for words_ids in X_test]"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"EAXYxxKpsqfh","executionInfo":{"status":"ok","timestamp":1672837975013,"user_tz":-60,"elapsed":555,"user":{"displayName":"Alexia Audevart","userId":"09723170522858788865"}}},"outputs":[],"source":["from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n","from sklearn.pipeline import Pipeline\n","from sklearn.linear_model import SGDClassifier"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"yiF8Jr3isqfj","executionInfo":{"status":"ok","timestamp":1672837981088,"user_tz":-60,"elapsed":214,"user":{"displayName":"Alexia Audevart","userId":"09723170522858788865"}}},"outputs":[],"source":["pipeline = Pipeline([\n","    ('vect', CountVectorizer()),\n","    ('tfidf', TfidfTransformer()),\n","    ('clf', SGDClassifier(max_iter=50)),\n","])"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"xP-rJcvAsqfl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672837986436,"user_tz":-60,"elapsed":3754,"user":{"displayName":"Alexia Audevart","userId":"09723170522858788865"}},"outputId":"2fe83ac1-3654-49ad-c857-cfa07508f595"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n","                ('clf', SGDClassifier(max_iter=50))])"]},"metadata":{},"execution_count":15}],"source":["pipeline.fit(X_train_text, y_train)"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"z_S4mxnMgyQT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672837995360,"user_tz":-60,"elapsed":214,"user":{"displayName":"Alexia Audevart","userId":"09723170522858788865"}},"outputId":"6ff1c9eb-43d2-4883-896c-cd83892973eb"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['00', '000', '10', ..., 'zoom', 'zorro', 'zu'], dtype=object)"]},"metadata":{},"execution_count":16}],"source":["pipeline[\"vect\"].get_feature_names_out()"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"ajHHQa5DjkcX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672838004227,"user_tz":-60,"elapsed":211,"user":{"displayName":"Alexia Audevart","userId":"09723170522858788865"}},"outputId":"2194adab-e612-4cb6-84ab-538bdb559a14"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["9773"]},"metadata":{},"execution_count":17}],"source":["pipeline[\"tfidf\"].n_features_in_"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"EFRy0Q2zgXMj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672838004530,"user_tz":-60,"elapsed":2,"user":{"displayName":"Alexia Audevart","userId":"09723170522858788865"}},"outputId":"c91010a0-0ee5-45b0-cd7d-871ba9f61392"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([6.74464447, 5.73304356, 3.00311327, ..., 7.6926839 , 8.03562865,\n","       8.18223212])"]},"metadata":{},"execution_count":18}],"source":["pipeline[\"tfidf\"].idf_"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"MAw67wJVsqfn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672838009451,"user_tz":-60,"elapsed":3417,"user":{"displayName":"Alexia Audevart","userId":"09723170522858788865"}},"outputId":"3c754db8-a036-4c90-db08-9298de9e9099"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.88496"]},"metadata":{},"execution_count":19}],"source":["pipeline.score(X_test_text, y_test)"]},{"cell_type":"markdown","metadata":{"id":"perl7uQKsqfp"},"source":["We get 88.5% accuracy, that's not too bad. But don't forget to check the ratio of positive reviews:"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"MwVsnqS4sqfp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672838017850,"user_tz":-60,"elapsed":212,"user":{"displayName":"Alexia Audevart","userId":"09723170522858788865"}},"outputId":"8ea84d5b-bc5d-450a-f387-6730c7f52564"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.5"]},"metadata":{},"execution_count":20}],"source":["y_test.mean()"]},{"cell_type":"markdown","metadata":{"id":"4U0nFU4lsqfs"},"source":["Let's try our model:"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"6q4PxPRRsqfs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672838064184,"user_tz":-60,"elapsed":2,"user":{"displayName":"Alexia Audevart","userId":"09723170522858788865"}},"outputId":"4d5b159c-90c1-4dfb-ff15-b250fde6b627"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":22}],"source":["res = pipeline.predict([\"this movie was really awesome\"])\n","res[0]"]},{"cell_type":"markdown","metadata":{"id":"hz4XcsL0sqfu"},"source":["### 1-2 Create a sequence classifier\n","\n","Create a sequence classifier using Keras:\n","* Use `keras.preprocessing.sequence.pad_sequences()` to preprocess `X_train`: this will create a 2D array of 25,000 rows (one per review) and `maxlen=500` columns. Reviews longer than 500 words will be cropped, while reviews shorter \n","than 500 words will be padded with zeros.\n"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"2dAgdALbsqfv","executionInfo":{"status":"ok","timestamp":1672838206730,"user_tz":-60,"elapsed":852,"user":{"displayName":"Alexia Audevart","userId":"09723170522858788865"}}},"outputs":[],"source":["maxlen = 500\n","X_train_trim = keras.preprocessing.sequence.pad_sequences(X_train, maxlen=maxlen)\n","X_test_trim = keras.preprocessing.sequence.pad_sequences(X_test, maxlen=maxlen)"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ypk4KWyS5uyM","executionInfo":{"status":"ok","timestamp":1672838229453,"user_tz":-60,"elapsed":3,"user":{"displayName":"Alexia Audevart","userId":"09723170522858788865"}},"outputId":"837b47de-2607-41bf-d7fb-ef4e50953c29"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(25000, 500)"]},"metadata":{},"execution_count":26}],"source":["X_train_trim.shape"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"fdyyAa95RKFT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672838231465,"user_tz":-60,"elapsed":214,"user":{"displayName":"Alexia Audevart","userId":"09723170522858788865"}},"outputId":"4e1de4f7-af9a-4a5b-c04a-fd00f1eff930"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(25000,)"]},"metadata":{},"execution_count":27}],"source":["y_train.shape"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HogpQgoy5uyM","executionInfo":{"status":"ok","timestamp":1672838234686,"user_tz":-60,"elapsed":207,"user":{"displayName":"Alexia Audevart","userId":"09723170522858788865"}},"outputId":"b894163a-a439-4746-9675-f8e5f3bd70aa"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["10000"]},"metadata":{},"execution_count":28}],"source":["num_words"]},{"cell_type":"markdown","metadata":{"id":"gyu8m4BC5uyM"},"source":["* The first layer in your model should be an `Embedding` layer, with `input_dim=num_words` and `output_dim=10`. The model will gradually learn to represent each of the 10,000 words as a 10-dimensional vector. So the next layer will receive 3D batchs of shape (batch size, 500, 10).\n","* Add one or more LSTM layers with 32 neurons each.\n","* The output layer should be a Dense layer with a sigmoid activation function, since this is a binary classification problem."]},{"cell_type":"code","execution_count":29,"metadata":{"id":"cvwZvFFgsqfx","executionInfo":{"status":"ok","timestamp":1672838537148,"user_tz":-60,"elapsed":3555,"user":{"displayName":"Alexia Audevart","userId":"09723170522858788865"}}},"outputs":[],"source":["model = keras.models.Sequential()\n","model.add(keras.layers.Embedding(input_dim=num_words, output_dim=10))\n","model.add(keras.layers.LSTM(32))\n","model.add(keras.layers.Dense(1, activation=\"sigmoid\"))"]},{"cell_type":"markdown","metadata":{"id":"czS_wQhu5uyM"},"source":["* When compiling the model, you should use the `binary_crossentropy` loss.\n","* Use `rmsprop` as optimizer.\n","* Fit the model for 10 epochs, using a batch size of 128 and `validation_split=0.2`."]},{"cell_type":"code","execution_count":30,"metadata":{"id":"b8A6Rt7vsqfz","executionInfo":{"status":"ok","timestamp":1672838537149,"user_tz":-60,"elapsed":19,"user":{"displayName":"Alexia Audevart","userId":"09723170522858788865"}}},"outputs":[],"source":["model.compile(loss=\"binary_crossentropy\", \n","              optimizer=\"rmsprop\", \n","              metrics=[\"accuracy\"])"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"qujTsJbhsqf1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672838537149,"user_tz":-60,"elapsed":18,"user":{"displayName":"Alexia Audevart","userId":"09723170522858788865"}},"outputId":"d5fa7319-e529-4cce-f49a-03c8d1417e1e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       (None, None, 10)          100000    \n","                                                                 \n"," lstm (LSTM)                 (None, 32)                5504      \n","                                                                 \n"," dense (Dense)               (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 105,537\n","Trainable params: 105,537\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"zz2QKL67sqf3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672838589311,"user_tz":-60,"elapsed":39648,"user":{"displayName":"Alexia Audevart","userId":"09723170522858788865"}},"outputId":"e502b4f5-5789-4190-933c-c262f06b5390"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","157/157 [==============================] - 11s 23ms/step - loss: 0.5685 - accuracy: 0.7199 - val_loss: 0.3810 - val_accuracy: 0.8500\n","Epoch 2/10\n","157/157 [==============================] - 3s 20ms/step - loss: 0.3457 - accuracy: 0.8625 - val_loss: 1.2210 - val_accuracy: 0.5832\n","Epoch 3/10\n","157/157 [==============================] - 3s 20ms/step - loss: 0.2713 - accuracy: 0.8960 - val_loss: 0.3465 - val_accuracy: 0.8528\n","Epoch 4/10\n","157/157 [==============================] - 3s 20ms/step - loss: 0.2249 - accuracy: 0.9169 - val_loss: 0.2878 - val_accuracy: 0.8860\n","Epoch 5/10\n","157/157 [==============================] - 3s 20ms/step - loss: 0.1967 - accuracy: 0.9277 - val_loss: 0.3635 - val_accuracy: 0.8436\n","Epoch 6/10\n","157/157 [==============================] - 3s 20ms/step - loss: 0.1714 - accuracy: 0.9392 - val_loss: 0.3597 - val_accuracy: 0.8874\n","Epoch 7/10\n","157/157 [==============================] - 3s 20ms/step - loss: 0.1574 - accuracy: 0.9449 - val_loss: 0.3410 - val_accuracy: 0.8862\n","Epoch 8/10\n","157/157 [==============================] - 3s 20ms/step - loss: 0.1482 - accuracy: 0.9498 - val_loss: 0.3000 - val_accuracy: 0.8768\n","Epoch 9/10\n","157/157 [==============================] - 3s 20ms/step - loss: 0.1294 - accuracy: 0.9545 - val_loss: 0.3676 - val_accuracy: 0.8806\n","Epoch 10/10\n","157/157 [==============================] - 3s 20ms/step - loss: 0.1253 - accuracy: 0.9572 - val_loss: 0.3372 - val_accuracy: 0.8658\n"]}],"source":["history = model.fit(X_train_trim, \n","                    y_train,\n","                    epochs=10, \n","                    batch_size=128, \n","                    validation_split=0.2)"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"O41sTbObsqf7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672838599623,"user_tz":-60,"elapsed":10334,"user":{"displayName":"Alexia Audevart","userId":"09723170522858788865"}},"outputId":"18c8384b-27e9-4a74-cdb9-b9e5b19ba760"},"outputs":[{"output_type":"stream","name":"stdout","text":["782/782 [==============================] - 6s 8ms/step - loss: 0.3576 - accuracy: 0.8612\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.35756465792655945, 0.8611999750137329]"]},"metadata":{},"execution_count":33}],"source":["model.evaluate(X_test_trim, y_test)"]},{"cell_type":"markdown","metadata":{"id":"ckz7XGM4sqf-"},"source":["## â—¢ 2 Bidirectional RNN"]},{"cell_type":"markdown","metadata":{"id":"cIa0m5Z_sqf_"},"source":["Update the previous sequence classification model to use a bidirectional LSTM. For this, you just need to wrap the LSTM layer in a `Bidirectional` layer. If the model overfits, try adding a dropout layer.\n","\n","Bidirectional LSTMs are an extension of traditional LSTMs that can improve model performance on sequence classification problems.\n","\n","In problems where all timesteps of the input sequence are available, Bidirectional LSTMs train two instead of one LSTMs on the input sequence. The first on the input sequence as-is and the second on a reversed copy of the input sequence. This can provide additional context to the network and result in faster and even fuller learning on the problem."]},{"cell_type":"code","execution_count":34,"metadata":{"id":"_FtP8j7-sqf_","executionInfo":{"status":"ok","timestamp":1672838626450,"user_tz":-60,"elapsed":701,"user":{"displayName":"Alexia Audevart","userId":"09723170522858788865"}}},"outputs":[],"source":["model = keras.models.Sequential()\n","model.add(keras.layers.Embedding(input_dim=num_words, output_dim=10))\n","model.add(keras.layers.Dropout(0.5))\n","model.add(keras.layers.Bidirectional(keras.layers.LSTM(32)))\n","model.add(keras.layers.Dense(1, activation=\"sigmoid\"))"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"I7rvXmC4ncXL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672838693184,"user_tz":-60,"elapsed":251,"user":{"displayName":"Alexia Audevart","userId":"09723170522858788865"}},"outputId":"666256a3-0431-4aae-f2cd-961e61f7ca81"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_1 (Embedding)     (None, None, 10)          100000    \n","                                                                 \n"," dropout (Dropout)           (None, None, 10)          0         \n","                                                                 \n"," bidirectional (Bidirectiona  (None, 64)               11008     \n"," l)                                                              \n","                                                                 \n"," dense_1 (Dense)             (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 111,073\n","Trainable params: 111,073\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"Oza3kZOmsqgC","executionInfo":{"status":"ok","timestamp":1672838693857,"user_tz":-60,"elapsed":0,"user":{"displayName":"Alexia Audevart","userId":"09723170522858788865"}}},"outputs":[],"source":["model.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics=[\"accuracy\"])"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"GH-iIBiTsqgE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672838867858,"user_tz":-60,"elapsed":173398,"user":{"displayName":"Alexia Audevart","userId":"09723170522858788865"}},"outputId":"50554104-f0f4-4e7a-c477-8a89afd0b2a0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","157/157 [==============================] - 9s 41ms/step - loss: 0.6218 - accuracy: 0.6583 - val_loss: 0.4819 - val_accuracy: 0.8126\n","Epoch 2/30\n","157/157 [==============================] - 6s 35ms/step - loss: 0.4046 - accuracy: 0.8329 - val_loss: 0.3343 - val_accuracy: 0.8664\n","Epoch 3/30\n","157/157 [==============================] - 6s 35ms/step - loss: 0.3146 - accuracy: 0.8717 - val_loss: 0.3185 - val_accuracy: 0.8772\n","Epoch 4/30\n","157/157 [==============================] - 6s 40ms/step - loss: 0.2740 - accuracy: 0.8929 - val_loss: 0.2697 - val_accuracy: 0.8938\n","Epoch 5/30\n","157/157 [==============================] - 6s 35ms/step - loss: 0.2481 - accuracy: 0.9046 - val_loss: 0.4687 - val_accuracy: 0.8360\n","Epoch 6/30\n","157/157 [==============================] - 6s 35ms/step - loss: 0.2235 - accuracy: 0.9165 - val_loss: 0.4921 - val_accuracy: 0.8562\n","Epoch 7/30\n","157/157 [==============================] - 6s 35ms/step - loss: 0.2052 - accuracy: 0.9233 - val_loss: 0.2629 - val_accuracy: 0.8922\n","Epoch 8/30\n","157/157 [==============================] - 6s 36ms/step - loss: 0.1956 - accuracy: 0.9282 - val_loss: 0.2779 - val_accuracy: 0.8978\n","Epoch 9/30\n","157/157 [==============================] - 6s 40ms/step - loss: 0.1863 - accuracy: 0.9319 - val_loss: 0.4811 - val_accuracy: 0.8482\n","Epoch 10/30\n","157/157 [==============================] - 6s 36ms/step - loss: 0.1724 - accuracy: 0.9356 - val_loss: 0.2864 - val_accuracy: 0.8862\n","Epoch 11/30\n","157/157 [==============================] - 6s 36ms/step - loss: 0.1665 - accuracy: 0.9395 - val_loss: 0.2727 - val_accuracy: 0.8958\n","Epoch 12/30\n","157/157 [==============================] - 6s 36ms/step - loss: 0.1600 - accuracy: 0.9415 - val_loss: 0.3163 - val_accuracy: 0.8742\n","Epoch 13/30\n","157/157 [==============================] - 6s 36ms/step - loss: 0.1548 - accuracy: 0.9444 - val_loss: 0.3013 - val_accuracy: 0.8952\n","Epoch 14/30\n","157/157 [==============================] - 6s 36ms/step - loss: 0.1493 - accuracy: 0.9462 - val_loss: 0.2981 - val_accuracy: 0.8820\n","Epoch 15/30\n","157/157 [==============================] - 6s 36ms/step - loss: 0.1485 - accuracy: 0.9449 - val_loss: 0.3374 - val_accuracy: 0.8884\n","Epoch 16/30\n","157/157 [==============================] - 6s 36ms/step - loss: 0.1442 - accuracy: 0.9473 - val_loss: 0.3440 - val_accuracy: 0.8894\n","Epoch 17/30\n","157/157 [==============================] - 6s 36ms/step - loss: 0.1391 - accuracy: 0.9475 - val_loss: 0.3320 - val_accuracy: 0.8900\n","Epoch 18/30\n","157/157 [==============================] - 6s 36ms/step - loss: 0.1320 - accuracy: 0.9516 - val_loss: 0.4405 - val_accuracy: 0.8746\n","Epoch 19/30\n","157/157 [==============================] - 6s 36ms/step - loss: 0.1320 - accuracy: 0.9520 - val_loss: 0.3584 - val_accuracy: 0.8878\n","Epoch 20/30\n","157/157 [==============================] - 6s 36ms/step - loss: 0.1309 - accuracy: 0.9534 - val_loss: 0.3494 - val_accuracy: 0.8882\n","Epoch 21/30\n","157/157 [==============================] - 6s 35ms/step - loss: 0.1267 - accuracy: 0.9532 - val_loss: 0.3589 - val_accuracy: 0.8902\n","Epoch 22/30\n","157/157 [==============================] - 6s 36ms/step - loss: 0.1223 - accuracy: 0.9563 - val_loss: 0.4978 - val_accuracy: 0.8498\n","Epoch 23/30\n","157/157 [==============================] - 6s 36ms/step - loss: 0.1206 - accuracy: 0.9576 - val_loss: 0.3379 - val_accuracy: 0.8804\n","Epoch 24/30\n","157/157 [==============================] - 6s 36ms/step - loss: 0.1196 - accuracy: 0.9560 - val_loss: 0.3161 - val_accuracy: 0.8902\n","Epoch 25/30\n","157/157 [==============================] - 6s 36ms/step - loss: 0.1167 - accuracy: 0.9577 - val_loss: 0.3936 - val_accuracy: 0.8880\n","Epoch 26/30\n","157/157 [==============================] - 6s 36ms/step - loss: 0.1133 - accuracy: 0.9582 - val_loss: 0.4444 - val_accuracy: 0.8826\n","Epoch 27/30\n","157/157 [==============================] - 6s 36ms/step - loss: 0.1167 - accuracy: 0.9581 - val_loss: 0.3954 - val_accuracy: 0.8808\n","Epoch 28/30\n","157/157 [==============================] - 6s 36ms/step - loss: 0.1131 - accuracy: 0.9585 - val_loss: 0.3561 - val_accuracy: 0.8872\n","Epoch 29/30\n","157/157 [==============================] - 6s 36ms/step - loss: 0.1108 - accuracy: 0.9600 - val_loss: 0.3305 - val_accuracy: 0.8902\n","Epoch 30/30\n","157/157 [==============================] - 6s 36ms/step - loss: 0.1088 - accuracy: 0.9591 - val_loss: 0.3819 - val_accuracy: 0.8650\n"]}],"source":["history = model.fit(X_train_trim, y_train,\n","                    epochs=30, batch_size=128, validation_split=0.2)"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"PXYV7CTcsqgG","scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672838878651,"user_tz":-60,"elapsed":10800,"user":{"displayName":"Alexia Audevart","userId":"09723170522858788865"}},"outputId":"e0e34137-e941-427b-992a-d99f097963d8"},"outputs":[{"output_type":"stream","name":"stdout","text":["782/782 [==============================] - 11s 14ms/step - loss: 0.4043 - accuracy: 0.8563\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.4042607545852661, 0.8563200235366821]"]},"metadata":{},"execution_count":38}],"source":["model.evaluate(X_test_trim, y_test)"]},{"cell_type":"markdown","metadata":{"id":"jf_t_3iO5uyN"},"source":["## â—¢ 3 Use Pretrained embeddings"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1T4nKF3k5uyN","outputId":"11100be7-f988-4cf6-f7b3-620d6736b68e"},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"]}],"source":["#https://www.tensorflow.org/tutorials/keras/text_classification_with_hub\n","\n","import tensorflow_hub as hub\n","\n","embedding = \"https://tfhub.dev/google/nnlm-en-dim50/2\"\n","hub_layer = hub.KerasLayer(embedding, input_shape=[], \n","                           dtype=tf.string, trainable=True)\n","\n","X_train_text_trim = keras.preprocessing.sequence.pad_sequences(X_train_text, maxlen=maxlen)\n","X_test_text_trim = keras.preprocessing.sequence.pad_sequences(X_test_text, maxlen=maxlen)\n","\n","X_train_text_trim.shape\n","\n","model = keras.models.Sequential()\n","model.add(hub_layer)\n","model.add(keras.layers.Dropout(0.5))\n","model.add(keras.layers.Bidirectional(keras.layers.LSTM(32)))\n","model.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n","\n","model.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics=[\"accuracy\"])\n","\n","\n","\n","history = model.fit(X_train_text_trim, y_train,\n","                    epochs=30, batch_size=128, validation_split=0.2)"]},{"cell_type":"markdown","metadata":{"id":"-h97SIfc5uyN"},"source":["## â—¢ 3 Retrieve the trained word embeddings and save them to disk\n","\n","Next, retrieve the word embeddings learned during training. The embeddings are weights of the Embedding layer in the model. The weights matrix is of shape (vocab_size, embedding_dimension).\n","\n","Obtain the weights from the model using get_layer() and get_weights(). \n","\n","The get_vocabulary() function provides the vocabulary to build a metadata file with one token per line."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ljMVqZ_45uyN"},"outputs":[],"source":["weights = model.get_layer('embedding').get_weights()[0]\n","vocab = word_index.keys()"]},{"cell_type":"markdown","metadata":{"id":"O78ICH5_5uyN"},"source":["Write the weights to disk.\n","\n","To use the [Embedding Projector](http://projector.tensorflow.org/?_gl=1*xa2gz2*_ga*MjE2NzI1MDI4LjE2NjQyODAwNDk.*_ga_W0YLR4190T*MTY3MDYwMTAwOC4yNi4xLjE2NzA2MDQxMDcuMC4wLjA.), you will upload two files in tab separated format: a file of vectors (containing the embedding), and a file of meta data (containing the words).\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gzaBfiwM5uyN"},"outputs":[],"source":["out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n","out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n","\n","for index, word in enumerate(vocab):\n","  if index == 0:\n","    continue  # skip 0, it's padding.\n","  vec = weights[index]\n","  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n","  out_m.write(word + \"\\n\")\n","out_v.close()\n","out_m.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S_-hQFZP5uyN","outputId":"42a92e79-e2d8-41fb-c452-d4a3d40de125"},"outputs":[{"data":{"text/plain":["<function dict.items>"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["word_index.keys"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"975iZx075uyN"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"tf2.10","language":"python","name":"tf2.10"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"}},"nbformat":4,"nbformat_minor":0}